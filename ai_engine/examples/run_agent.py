#!/usr/bin/env python3
# ---------------------------------------------------------
# Field Nine OS: Agent ì‹¤í–‰ ì˜ˆì‹œ
# OpenAI GPT-4o ì—°ë™ ì™„ì „ ì˜ˆì œ
# ---------------------------------------------------------

import asyncio
import os
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from ai_engine.core import (
    AgentController,
    AgentState,
    QualityAgent,
    create_default_registry,
    ThoughtProcess,
    Action,
    Observation
)


async def main():
    """
    Field Nine OS Agent ì‹¤í–‰ ì˜ˆì‹œ

    ì‹¤í–‰ ë°©ë²•:
        1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
           export OPENAI_API_KEY="sk-..."
           export SERPER_API_KEY="..."  # (ì„ íƒ) ì›¹ ê²€ìƒ‰ìš©

        2. ì‹¤í–‰:
           cd field-nine-solutions
           python -m ai_engine.examples.run_agent
    """

    print("=" * 60)
    print("ğŸš€ Field Nine OS - Level 3 AI Agent")
    print("=" * 60)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("   export OPENAI_API_KEY='sk-...'")
        return

    # ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±
    tools = create_default_registry({
        "serper_api_key": os.getenv("SERPER_API_KEY"),
        # "supabase": supabase_client,  # Supabase í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œ
    })

    print(f"ğŸ“¦ ë“±ë¡ëœ ë„êµ¬: {tools.list_tools()}")

    # í’ˆì§ˆ ê²€ìˆ˜ ì—ì´ì „íŠ¸ ìƒì„± (ì„ íƒì )
    quality_agent = QualityAgent(
        min_quality_threshold=0.7,
        max_retries=2
    )

    # ì½œë°± í•¨ìˆ˜ ì •ì˜
    def on_thought(content: str):
        """ì‹¤ì‹œê°„ Thought ìŠ¤íŠ¸ë¦¬ë°"""
        print(content, end="", flush=True)

    def on_action(action: Action):
        """Action ì‹¤í–‰ ì•Œë¦¼"""
        print(f"\nğŸ”§ ë„êµ¬ ì‹¤í–‰: {action.tool_name}")

    def on_observation(obs: Observation):
        """Observation ê²°ê³¼"""
        status = "âœ…" if obs.success else "âŒ"
        print(f"{status} ê²°ê³¼: {str(obs.result)[:200]}...")

    def on_state_change(state: AgentState):
        """ìƒíƒœ ë³€ê²½ ì•Œë¦¼"""
        state_icons = {
            AgentState.THINKING: "ğŸ¤”",
            AgentState.ACTING: "âš¡",
            AgentState.OBSERVING: "ğŸ‘ï¸",
            AgentState.REVIEWING: "ğŸ”",
            AgentState.COMPLETED: "âœ…",
            AgentState.FAILED: "âŒ",
        }
        icon = state_icons.get(state, "ğŸ“Œ")
        print(f"\n{icon} ìƒíƒœ: {state.value}")

    # ì—ì´ì „íŠ¸ ìƒì„±
    agent = AgentController(
        agent_id="field-nine-agent",
        openai_api_key=api_key,
        tools=tools,
        quality_agent=quality_agent,
        model="gpt-4o",
        max_iterations=5,
        quality_threshold=0.7,
        enable_streaming=True,
        verbose=True,
        on_thought=on_thought,
        on_action=on_action,
        on_observation=on_observation,
        on_state_change=on_state_change,
    )

    print("\n" + "=" * 60)

    # í…ŒìŠ¤íŠ¸ íƒœìŠ¤í¬ ì‹¤í–‰
    tasks = [
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ íŒ¨ì…˜ íŠ¸ë Œë“œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì¤˜",
        # "2026ë…„ í•œêµ­ ìŠ¤íŠ¸ë¦¿ íŒ¨ì…˜ íŠ¸ë Œë“œë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•´ì¤˜",
        # "Field Nineì˜ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì¤˜",
    ]

    for task in tasks:
        print(f"\nğŸ¯ Task: {task}")
        print("-" * 60)

        result = await agent.execute(task)

        print("\n" + "=" * 60)
        print("ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        print(f"  - ì„±ê³µ: {result['success']}")
        print(f"  - ë°˜ë³µ íšŸìˆ˜: {result['iterations']}")
        print(f"  - ìƒíƒœ: {result['state']}")

        if result.get("usage_stats"):
            stats = result["usage_stats"]
            print(f"\nğŸ’° ì‚¬ìš©ëŸ‰:")
            print(f"  - ì´ í† í°: {stats.get('usage', {}).get('total_tokens', 0)}")
            print(f"  - ì˜ˆìƒ ë¹„ìš©: ${stats.get('usage', {}).get('estimated_cost_usd', 0):.4f}")

        if result.get("error"):
            print(f"\nâŒ ì—ëŸ¬: {result['error']}")

        print("=" * 60)


async def streaming_example():
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ ì˜ˆì‹œ

    ì—ì´ì „íŠ¸ì˜ ëª¨ë“  ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    tools = create_default_registry()

    agent = AgentController(
        agent_id="streaming-agent",
        openai_api_key=api_key,
        tools=tools,
        model="gpt-4o",
        max_iterations=3,
        enable_streaming=True,
        verbose=False,  # ì§ì ‘ ì¶œë ¥í•  ê²ƒì´ë¯€ë¡œ ë¹„í™œì„±í™”
    )

    print("ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‹¤í–‰")
    print("-" * 60)

    task = "ê°„ë‹¨í•œ ì¸ì‚¬ë§ì„ ìƒì„±í•´ì¤˜"

    async for update in agent.execute_streaming(task):
        update_type = update.get("type")

        if update_type == "start":
            print(f"ğŸ¯ Task ID: {update['task_id']}")

        elif update_type == "iteration_start":
            print(f"\n--- Iteration {update['iteration']} ---")

        elif update_type == "state":
            print(f"ğŸ“Œ State: {update['state']}")

        elif update_type == "thought_chunk":
            print(update["content"], end="", flush=True)

        elif update_type == "thought_complete":
            print("\nâœ… Thought complete")

        elif update_type == "action":
            print(f"âš¡ Action: {update['action']}")

        elif update_type == "observation":
            print(f"ğŸ‘ï¸ Observation: {update['observation']}")

        elif update_type == "complete":
            print(f"\nğŸ‰ Complete: {update['result'][:200]}...")

        elif update_type == "max_iterations":
            print(f"âš ï¸ Max iterations reached: {update['iterations']}")


async def simple_chat_example():
    """
    ê°„ë‹¨í•œ OpenAI ì±„íŒ… ì˜ˆì‹œ

    LLM Providerë§Œ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ëŒ€í™”
    """
    from ai_engine.core import OpenAIProvider, ChatMessage, MessageRole

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    # Provider ìƒì„±
    provider = OpenAIProvider(
        api_key=api_key,
        model="gpt-4o",
        temperature=0.7,
        on_stream_chunk=lambda c: print(c, end="", flush=True),
    )

    print("ğŸ’¬ ê°„ë‹¨í•œ ì±„íŒ… ì˜ˆì‹œ")
    print("-" * 60)

    messages = [
        ChatMessage(
            role=MessageRole.SYSTEM,
            content="ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ AI ë¹„ì„œì•¼."
        ),
        ChatMessage(
            role=MessageRole.USER,
            content="ì•ˆë…•í•˜ì„¸ìš”! Field Nineì— ëŒ€í•´ ì†Œê°œí•´ì¤„ ìˆ˜ ìˆë‚˜ìš”?"
        )
    ]

    # ì¼ë°˜ í˜¸ì¶œ
    print("ğŸ“ ì¼ë°˜ ì‘ë‹µ:")
    response = await provider.chat(messages)
    print(response.content)
    print(f"\nğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {response.usage}")

    # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    print("\nğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:")
    messages.append(ChatMessage(
        role=MessageRole.ASSISTANT,
        content=response.content or ""
    ))
    messages.append(ChatMessage(
        role=MessageRole.USER,
        content="ë” ìì„¸íˆ ì•Œë ¤ì¤˜"
    ))

    async for chunk in provider.chat_stream(messages):
        if chunk.content:
            print(chunk.content, end="", flush=True)
        if chunk.is_complete:
            print("\nâœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")

    # ì‚¬ìš©ëŸ‰ í†µê³„
    print(f"\nğŸ’° ì´ ì‚¬ìš©ëŸ‰: {provider.get_usage_stats()}")


async def function_calling_example():
    """
    Function Calling ì˜ˆì‹œ

    ë„êµ¬ë¥¼ ì‚¬ìš©í•œ LLM í˜¸ì¶œ
    """
    from ai_engine.core import OpenAIProvider, ChatMessage, MessageRole

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    provider = OpenAIProvider(
        api_key=api_key,
        model="gpt-4o",
    )

    # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ì •ì˜
    tools = [
        {
            "name": "get_weather",
            "description": "Get the current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city name"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "default": "celsius"
                    }
                },
                "required": ["location"]
            }
        },
        {
            "name": "search_products",
            "description": "Search for fashion products",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search query"
                    },
                    "category": {
                        "type": "string",
                        "enum": ["tops", "bottoms", "shoes", "accessories"]
                    }
                },
                "required": ["query"]
            }
        }
    ]

    print("ğŸ”§ Function Calling ì˜ˆì‹œ")
    print("-" * 60)

    messages = [
        ChatMessage(
            role=MessageRole.SYSTEM,
            content="You are a helpful assistant that can check weather and search products."
        ),
        ChatMessage(
            role=MessageRole.USER,
            content="ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì£¼ê³ , ìš”ì¦˜ ì¸ê¸°ìˆëŠ” ìŠ¤ë‹ˆì»¤ì¦ˆ ê²€ìƒ‰í•´ì¤˜"
        )
    ]

    response = await provider.chat(messages, tools)

    print(f"ğŸ“ ì‘ë‹µ: {response.content}")
    print(f"\nğŸ”§ Tool Calls:")
    for tc in response.tool_calls:
        print(f"  - {tc.name}: {tc.arguments}")

    # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì— ì „ë‹¬í•˜ëŠ” ì˜ˆì‹œ
    if response.tool_calls:
        messages.append(ChatMessage(
            role=MessageRole.ASSISTANT,
            content=response.content or "",
            tool_calls=[{
                "id": tc.id,
                "name": tc.name,
                "arguments": tc.arguments
            } for tc in response.tool_calls]
        ))

        # Mock tool results
        for tc in response.tool_calls:
            if tc.name == "get_weather":
                tool_result = {"temperature": 15, "condition": "ë§‘ìŒ", "humidity": 45}
            elif tc.name == "search_products":
                tool_result = {"products": [
                    {"name": "Nike Air Max", "price": 159000},
                    {"name": "Adidas Samba", "price": 139000}
                ]}
            else:
                tool_result = {"error": "Unknown tool"}

            messages.append(ChatMessage(
                role=MessageRole.TOOL,
                content=str(tool_result),
                tool_call_id=tc.id
            ))

        # Final response with tool results
        final_response = await provider.chat(messages)
        print(f"\nğŸ“‹ ìµœì¢… ì‘ë‹µ:\n{final_response.content}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Field Nine OS Agent ì˜ˆì‹œ")
    parser.add_argument(
        "--mode",
        choices=["full", "streaming", "chat", "function"],
        default="full",
        help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ"
    )

    args = parser.parse_args()

    if args.mode == "full":
        asyncio.run(main())
    elif args.mode == "streaming":
        asyncio.run(streaming_example())
    elif args.mode == "chat":
        asyncio.run(simple_chat_example())
    elif args.mode == "function":
        asyncio.run(function_calling_example())
